akka {
  loglevel = info
  actor {
    provider = cluster
    default-dispatcher {
	  type = Dispatcher
	  executor = "com.zero.ddd.akka.cluster.core.helper.MonitorAbleForkJoinPoolConfigurator"
	  fork-join-executor {
	    parallelism = 4
	  }
	  throughput = 100
	}
    serializers {
      jackson-json = "akka.serialization.jackson.JacksonJsonSerializer"
      jackson-cbor = "akka.serialization.jackson.JacksonCborSerializer"
      proto = "akka.remote.serialization.ProtobufSerializer"
      self-proto = "com.zero.ddd.akka.cluster.core.initializer.serializer.ProtobufSerializer"
    }
    serialization-bindings {
      "com.google.protobuf.Message" = proto
      "com.zero.ddd.akka.cluster.core.msg.ClusterMessage" = jackson-cbor
      "com.zero.ddd.akka.cluster.core.initializer.serializer.SelfProtoBufObject" = self-proto
    }
  }
  persistence {
    max-concurrent-recoveries = 500
    journal {
      plugin = "jdbc-journal"
    }
    snapshot-store {
      plugin = "jdbc-snapshot-store"
    }
  }
}

akka.cluster.sharding.passivation {
  strategy = default-strategy
}

pinned-dispatcher {
    type = PinnedDispatcher
	executor = "thread-pool-executor"
	thread-pool-executor {
		allow-core-timeout = off
  	}
}

blocking-io-dispatcher {
  type = Dispatcher
  executor = "com.zero.ddd.akka.cluster.core.helper.MonitorAbleExecutorServiceConfigurator"
  thread-pool-executor {
  	core-size = 10
  	max-size = 180
  	keep-alive-time = 120
  	queue-size = 20
  }
  throughput = 1
  shutdown-timeout = 600s
}

client-actor {
  special-mailbox {
    mailbox-type = "akka.dispatch.UnboundedControlAwareMailbox"
  }
}

akka.serialization.jackson.jackson-json.compression {
  # Compression algorithm.
  # - off  : no compression
  # - gzip : using common java gzip
  # - lz4 : using lz4-java
  algorithm = gzip

  # If compression is enabled with the `algorithm` setting the payload is compressed
  # when it's larger than this value.
  compress-larger-than = 4 KiB
}